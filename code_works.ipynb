{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3f53fbb-6926-40eb-b9aa-c9505949264d",
   "metadata": {},
   "source": [
    "# Code Works\n",
    "This notebook contains examples of LLMs doing the following:\n",
    "- Add comments and docstrings to a given piece of Python code\n",
    "- Write unit test cases for the functions in a given piece of Python code\n",
    "\n",
    "LLMs used include:\n",
    "- OpenAI ChatGPT-4o\n",
    "- Anhropic Clause 3.5 Sonnet\n",
    "- Google Gemini 2.0 Flash\n",
    "\n",
    "The above will be developed as Gradio apps so we could try them out. Let's go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48c41a3-751a-4cdb-82e5-4a846709b3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import io\n",
    "import sys\n",
    "import textwrap\n",
    "import datetime\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from openai import OpenAI\n",
    "import google.generativeai as genai\n",
    "import anthropic\n",
    "\n",
    "from IPython.display import Markdown, display, update_display\n",
    "import gradio as gr\n",
    "\n",
    "# environment\n",
    "load_dotenv(override=True)\n",
    "OPENAI_API_KEY    = os.getenv('OPENAI_API_KEY')\n",
    "ANTHROPIC_API_KEY = os.getenv('ANTHROPIC_API_KEY')\n",
    "GOOGLE_API_KEY    = os.getenv('GOOGLE_API_KEY')\n",
    "\n",
    "# initialize\n",
    "openai = OpenAI(api_key=OPENAI_API_KEY)\n",
    "claude = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)\n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "# LLM models\n",
    "OPENAI_MODEL = \"gpt-4o\"\n",
    "CLAUDE_MODEL = \"claude-3-5-sonnet-latest\"\n",
    "GEMINI_MODEL = \"gemini-2.0-flash-exp\"  # \"gemini-1.5-pro\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32267acc-6869-48bc-9f50-2d862587fcdd",
   "metadata": {},
   "source": [
    "----\n",
    "## LLM Call Functions\n",
    "Below are some generic LLM functions that will be utilized by the two Gradio apps that we will be seeing shortly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b27328b-b026-4250-b4ba-132a35ecd479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------- Providers ---------\n",
    "def call_anthropic(sys_prompt: str, prompt: str, temperature: float = 0.2, max_tokens: int = 4096) -> str:\n",
    "    print(datetime.datetime.now(), '-->', 'call_anthropic()')\n",
    "    resp = claude.messages.create(\n",
    "        model=CLAUDE_MODEL,\n",
    "        max_tokens=max_tokens,\n",
    "        temperature=temperature,\n",
    "        system=sys_prompt,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    )\n",
    "    parts = []\n",
    "    for block in resp.content:\n",
    "        if getattr(block, \"type\", None) == \"text\":\n",
    "            parts.append(block.text)\n",
    "    return \"\".join(parts).strip() or \"# Empty response from Anthropic.\"\n",
    "\n",
    "def call_openai(sys_prompt: str, prompt: str, temperature: float = 0.2, max_tokens: int = 4096) -> str:\n",
    "    print(datetime.datetime.now(), '-->', 'call_openai()')\n",
    "    resp = openai.chat.completions.create(\n",
    "        model=OPENAI_MODEL,\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": sys_prompt},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "    )\n",
    "    text = resp.choices[0].message.content or \"\"\n",
    "    return text.strip().removeprefix(\"```python\").removesuffix(\"```\").strip() or \"# Empty response from OpenAI.\"\n",
    "\n",
    "def call_gemini(sys_prompt: str, prompt: str, temperature: float = 0.2, max_tokens: int = 4096) -> str:\n",
    "    print(datetime.datetime.now(), '-->', 'call_gemini()')\n",
    "    model = genai.GenerativeModel(GEMINI_MODEL, system_instruction=sys_prompt)\n",
    "    resp = model.generate_content(\n",
    "        prompt,\n",
    "        generation_config=genai.types.GenerationConfig(\n",
    "            temperature=temperature,\n",
    "            max_output_tokens=max_tokens,\n",
    "        ),\n",
    "    )\n",
    "    text = (resp.text or \"\").strip()\n",
    "    return text.removeprefix(\"```python\").removesuffix(\"```\").strip() or \"# Empty response from Gemini.\"\n",
    "\n",
    "# --------- Router ---------\n",
    "def router_func(sys_prompt: str, prompt: str, provider: str, temperature: float = 0.2) -> str:\n",
    "    try:\n",
    "        if provider == \"Anthropic Claude\":\n",
    "            return call_anthropic(sys_prompt, prompt, temperature)\n",
    "        elif provider == \"OpenAI GPT\":\n",
    "            return call_openai(sys_prompt, prompt, temperature)\n",
    "        elif provider == \"Google Gemini\":\n",
    "            return call_gemini(sys_prompt, prompt, temperature)\n",
    "        else:\n",
    "            return \"# Unknown provider selected.\"\n",
    "    except Exception as e:\n",
    "        return f\"# Error: {e}\\n# Check the selected provider's SDK, model name, and API key.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a08958b-d38e-4f8b-9325-bb3ea0e0ecc7",
   "metadata": {},
   "source": [
    "----\n",
    "## Gradio App 1: Add comments and docstrings to Python code\n",
    "Here we will build a Gradio app that takes a Python script and adds comments/docstrings to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e28e292-cc98-4356-9ed8-04202191350b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\\\n",
    "You are a Python code reviewer. Add clear, PEP 257-compliant docstrings to all public\n",
    "functions/classes/modules and concise inline comments where helpful. Preserve logic and\n",
    "formatting as much as possible. If code has issues, fix only what is necessary to make\n",
    "the docstrings and comments accurate. Return *only* the fully updated Python code.\n",
    "\"\"\"\n",
    "\n",
    "# A compact instruction that encourages structured, deterministic output.\n",
    "USER_INSTRUCTION_TEMPLATE = \"\"\"\\\n",
    "Rewrite the following Python script by adding:\n",
    "1) A module-level docstring at the top summarizing purpose and usage.\n",
    "2) Docstrings for public functions/classes with arguments, returns, raises.\n",
    "3) Helpful inline comments for non-obvious logic.\n",
    "4) Keep imports, names, and structure stable unless a tiny refactor improves clarity.\n",
    "5) Do not wrap code in triple backticks; return only the code.\n",
    "\n",
    "Python script:\n",
    "{code}\n",
    "\"\"\"\n",
    "\n",
    "# --------- Custom Function ---------\n",
    "def annotate_code(py_code: str, provider: str, temperature: float = 0.2) -> str:\n",
    "    if not py_code or not py_code.strip():\n",
    "        return \"# Please paste a Python script on the left.\"\n",
    "    prompt = USER_INSTRUCTION_TEMPLATE.format(code=py_code)\n",
    "    return router_func(SYSTEM_PROMPT, prompt, provider, temperature)\n",
    "\n",
    "# --------- Gradio UI ---------\n",
    "with gr.Blocks(title=\"Docstring & Comments Enhancer\") as demo:\n",
    "    gr.Markdown(\"## Python Comment & Docstring Enhancer\")\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            provider = gr.Dropdown(\n",
    "                choices=[\n",
    "                    \"Anthropic Claude\",\n",
    "                    \"OpenAI GPT\",\n",
    "                    \"Google Gemini\",\n",
    "                ],\n",
    "                value=\"Anthropic Claude\",\n",
    "                label=\"LLM Provider / Model\",\n",
    "            )\n",
    "            code_in = gr.Code(\n",
    "                label=\"Paste your Python script\",\n",
    "                language=\"python\",\n",
    "                lines=24,\n",
    "                value=textwrap.dedent(\n",
    "                    \"\"\"\\\n",
    "                    import math\n",
    "\n",
    "                    def hypotenuse(a, b):\n",
    "                        return (a**2 + b**2) ** 0.5\n",
    "\n",
    "                    class Accumulator:\n",
    "                        def __init__(self):\n",
    "                            self.total = 0\n",
    "                        def add(self, x):\n",
    "                            self.total += x\n",
    "                            return self.total\n",
    "\n",
    "                    if __name__ == \"__main__\":\n",
    "                        print(hypotenuse(3,4))\n",
    "                        acc = Accumulator()\n",
    "                        for i in range(5):\n",
    "                            print(acc.add(i))\n",
    "                    \"\"\"\n",
    "                ),\n",
    "            )\n",
    "            temperature = gr.Slider(0.0, 1.0, value=0.2, step=0.05, label=\"Temperature\")\n",
    "            run_btn = gr.Button(\"Enhance\", variant=\"primary\")\n",
    "        with gr.Column():\n",
    "            code_out = gr.Code(label=\"Commented & Documented Code\", language=\"python\", lines=24)\n",
    "\n",
    "    run_btn.click(\n",
    "        fn=lambda c, p, t: annotate_code(c, p, t),\n",
    "        inputs=[code_in, provider, temperature],\n",
    "        outputs=code_out,\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33783f97-ae56-479d-b966-95cc654df3d6",
   "metadata": {},
   "source": [
    "----\n",
    "## Gradio App 2: Write unit test cases for given functions\n",
    "Here we will build a Gradio app that write unit test cases for given python functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36116249-a860-417e-a8a0-b7bfb0870ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\\\n",
    "You are an expert Python developer who writes thorough, concise, and runnable unit tests\n",
    "using the unittest framework. Given Python code, your job is to:\n",
    "1) Identify all public functions and classes.\n",
    "2) Write unittest.TestCase subclasses that cover typical cases, edge cases, and error cases.\n",
    "3) Include any necessary imports and mock usage if needed.\n",
    "4) Keep the tests clear and idiomatic, avoiding redundant cases.\n",
    "5) Output only the Python test code, no explanations or formatting fences.\n",
    "\"\"\"\n",
    "\n",
    "# A compact instruction that encourages structured, deterministic output.\n",
    "USER_INSTRUCTION_TEMPLATE = \"\"\"\\\n",
    "Write Python unit tests for the following code:\n",
    "\n",
    "{code}\n",
    "\"\"\"\n",
    "\n",
    "# --------- Custom Function ---------\n",
    "def generate_tests(py_code: str, provider: str, temperature: float = 0.2) -> str:\n",
    "    if not py_code or not py_code.strip():\n",
    "        return \"# Please paste a Python script on the left.\"\n",
    "    prompt = USER_INSTRUCTION_TEMPLATE.format(code=py_code)\n",
    "    return router_func(SYSTEM_PROMPT, prompt, provider, temperature)\n",
    "\n",
    "# --------- Gradio UI ---------\n",
    "with gr.Blocks(title=\"Python Unit Test Generator\") as demo:\n",
    "    gr.Markdown(\"## ðŸ§ª Python Unit Test Generator\")\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            provider = gr.Dropdown(\n",
    "                choices=[\n",
    "                    \"Anthropic Claude\",\n",
    "                    \"OpenAI GPT\",\n",
    "                    \"Google Gemini\",\n",
    "                ],\n",
    "                value=\"Anthropic Claude\",\n",
    "                label=\"LLM Provider / Model\",\n",
    "            )\n",
    "            code_in = gr.Code(\n",
    "                label=\"Paste Python code to test\",\n",
    "                language=\"python\",\n",
    "                lines=20,\n",
    "                value=textwrap.dedent(\"\"\"\\\n",
    "                    def add(a, b):\n",
    "                        return a + b\n",
    "\n",
    "                    def divide(a, b):\n",
    "                        return a / b\n",
    "                \"\"\"),\n",
    "            )\n",
    "            # temperature = gr.Slider(0.0, 1.0, value=0.2, step=0.05, label=\"Temperature\")\n",
    "            run_btn = gr.Button(\"Generate Unit Tests\", variant=\"primary\")\n",
    "        with gr.Column():\n",
    "            code_out = gr.Code(label=\"Generated Unit Tests\", language=\"python\", lines=20)\n",
    "\n",
    "    run_btn.click(\n",
    "        # fn=lambda c, p, t: generate_tests(c, p, t),\n",
    "        # inputs=[code_in, provider, temperature],\n",
    "        fn=lambda c, p: generate_tests(c, p),\n",
    "        inputs=[code_in, provider],\n",
    "        outputs=code_out,\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms-env",
   "language": "python",
   "name": "llms-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
