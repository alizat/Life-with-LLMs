{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# The Product Pricer -- Continued\n",
        "In [part 1](llm_regression.ipynb), we demonstrated the use of *LLM frontier models* to perform regression on products from the [Amazon reviews dataset](https://huggingface.co/datasets/McAuley-Lab/Amazon-Reviews-2023) and contrasted them against baseline machine learning models such as *Support Vector Machines* and *Random Forest*.\n",
        "\n",
        "Here in part 2, we will attempt to fine-tune an open-source model, [Llama-3.1-8B](https://huggingface.co/meta-llama/Llama-3.1-8B), to see if we can match or exceed the performances observed by the frontier models in part 1.\n",
        "\n",
        "Let's go!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Before we move on\n",
        "It is assumed that you are running this notebook on Google Colab (or similar) with a T4 machine that has a 16GB GPU."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHsssBgWM_l0"
      },
      "source": [
        "## Necessary libraries\n",
        "When you run the pip installs below, you may get an error from pip complaining about an incompatible version of fsspec.\n",
        "You should ignore that error! The version of fsspec is the right version, needed by HuggingFace.\n",
        "So please run the pip installs as they appear below, and look the other way if you get an error!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDyR63OTNUJ6",
        "outputId": "e3a1a8b6-28a3-4fe4-cf68-554f17c02f52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m908.2/908.2 MB\u001b[0m \u001b[31m594.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m131.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m116.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m109.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m70.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m107.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m122.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.6/209.6 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m134.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m336.6/336.6 kB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.8/374.8 kB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.9/313.9 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m148.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m124.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.3 which is incompatible.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.9.0 which is incompatible.\n",
            "google-adk 1.16.0 requires requests<3.0.0,>=2.32.4, but you have requests 2.32.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# !pip install -q --upgrade torch==2.5.1+cu124 torchvision==0.20.1+cu124 torchaudio==2.5.1+cu124 --index-url https://download.pytorch.org/whl/cu124\n",
        "# !pip install -q --upgrade requests==2.32.3 bitsandbytes==0.46.0 transformers==4.48.3 accelerate==1.3.0 datasets==3.2.0 peft==0.14.0 trl==0.14.0 matplotlib wandb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-yikV8pRBer9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "from google.colab import userdata\n",
        "from huggingface_hub import login\n",
        "import torch\n",
        "import transformers\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, set_seed, BitsAndBytesConfig\n",
        "from datasets import load_dataset, Dataset, DatasetDict\n",
        "import wandb\n",
        "from peft import LoraConfig\n",
        "from trl import SFTTrainer, SFTConfig\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uuTX-xonNeOK"
      },
      "outputs": [],
      "source": [
        "BASE_MODEL = \"meta-llama/Meta-Llama-3.1-8B\"\n",
        "PROJECT_NAME = \"pricer\"\n",
        "HF_USER = \"ALiZaTo\"  # your HF name here!\n",
        "\n",
        "# Data\n",
        "DATASET_NAME = \"ed-donner/pricer-data\"\n",
        "MAX_SEQUENCE_LENGTH = 182\n",
        "\n",
        "# Run name for saving the model in the hub\n",
        "RUN_NAME =  f\"{datetime.now():%Y-%m-%d_%H.%M.%S}\"\n",
        "PROJECT_RUN_NAME = f\"{PROJECT_NAME}-{RUN_NAME}\"\n",
        "HUB_MODEL_NAME = f\"{HF_USER}/{PROJECT_RUN_NAME}\"\n",
        "\n",
        "# Hyperparameters for QLoRA\n",
        "LORA_R = 32\n",
        "LORA_ALPHA = 64  # usually set to 2x LORA_R\n",
        "TARGET_MODULES = [\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\"]\n",
        "LORA_DROPOUT = 0.1\n",
        "QUANT_4_BIT = True\n",
        "\n",
        "# Hyperparameters for Training\n",
        "EPOCHS = 1      # you can do more epochs if you wish, but only 1 is needed - more is probably overkill\n",
        "BATCH_SIZE = 4  # on an A100 box, this can go up to 16\n",
        "GRADIENT_ACCUMULATION_STEPS = 1\n",
        "LEARNING_RATE = 1e-4\n",
        "LR_SCHEDULER_TYPE = 'cosine'\n",
        "WARMUP_RATIO = 0.03\n",
        "OPTIMIZER = \"paged_adamw_32bit\"  # Adam with weight decay (converges fast by storing rolling avg of previous gradients, uses more memory).\n",
        "# check out other options here: https://huggingface.co/docs/transformers/main/en/perf_train_gpu_one#optimizers\n",
        "\n",
        "# Admin config\n",
        "STEPS = 50           # evaluation will be printed every 50 steps\n",
        "SAVE_STEPS = 2000    # a model will be uploaded to the hub every 2000 steps\n",
        "LOG_TO_WANDB = True  # whether to log to wandb (weights and biases)\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "QyHOj-c4FmkM",
        "outputId": "2443b993-8522-463b-d644-30907b84b7eb"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ALiZaTo/pricer-2025-10-18_19.19.46'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "HUB_MODEL_NAME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JArT3QAQAjx"
      },
      "source": [
        "## Log in to HuggingFace and Weights & Biases\n",
        "\n",
        "If you don't already have a HuggingFace account, visit https://huggingface.co to sign up and create a token.\n",
        "\n",
        "Then select the Secrets for this Notebook by clicking on the key icon in the left, and add a new secret called `HF_TOKEN` with the value as your token.\n",
        "\n",
        "Repeat this for weightsandbiases at https://wandb.ai and add a secret called `WANDB_API_KEY`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WyFPZeMcM88v"
      },
      "outputs": [],
      "source": [
        "# Log in to HuggingFace\n",
        "hf_token = userdata.get('HF_TOKEN')\n",
        "login(hf_token, add_to_git_credential=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJNOv3cVvJ68",
        "outputId": "4c9333ca-ac02-42a9-8025-877f855e4e97"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33maliezzat1985\u001b[0m (\u001b[33maliezzat1985-synapse-analytics\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        }
      ],
      "source": [
        "# Log in to Weights & Biases\n",
        "wandb_api_key = userdata.get('WANDB_API_KEY')\n",
        "os.environ[\"WANDB_API_KEY\"] = wandb_api_key\n",
        "wandb.login()\n",
        "\n",
        "# Configure Weights & Biases to record against our project\n",
        "os.environ[\"WANDB_PROJECT\"] = PROJECT_NAME\n",
        "os.environ[\"WANDB_LOG_MODEL\"] = \"checkpoint\" if LOG_TO_WANDB else \"end\"\n",
        "os.environ[\"WANDB_WATCH\"] = \"gradients\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "8_SUsKqA23Gc",
        "outputId": "618859d9-245a-4c01-a202-e8cfb90db5e0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.22.2"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251018_192133-vyuygla1</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/aliezzat1985-synapse-analytics/pricer/runs/vyuygla1' target=\"_blank\">2025-10-18_19.19.46</a></strong> to <a href='https://wandb.ai/aliezzat1985-synapse-analytics/pricer' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/aliezzat1985-synapse-analytics/pricer' target=\"_blank\">https://wandb.ai/aliezzat1985-synapse-analytics/pricer</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/aliezzat1985-synapse-analytics/pricer/runs/vyuygla1' target=\"_blank\">https://wandb.ai/aliezzat1985-synapse-analytics/pricer/runs/vyuygla1</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "if LOG_TO_WANDB:\n",
        "  wandb.init(project=PROJECT_NAME, name=RUN_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJWQ0a3wZ0Bw"
      },
      "source": [
        "## Tokenizer and Model\n",
        "The model is \"quantized\". Specifically, we are reducing the precision to 4 bits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9lb7M9xn46wx"
      },
      "outputs": [],
      "source": [
        "# pick the right quantization\n",
        "if QUANT_4_BIT:\n",
        "  quant_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "    bnb_4bit_quant_type=\"nf4\"\n",
        "  )\n",
        "else:\n",
        "  quant_config = BitsAndBytesConfig(\n",
        "    load_in_8bit=True,\n",
        "    bnb_8bit_compute_dtype=torch.bfloat16\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418,
          "referenced_widgets": [
            "24dbab747a87418d8e97cde8874a29b2",
            "89a7f049ad85439aa7925c2b0dfde932",
            "8cecc93d642f47e1ac1c899c11077611",
            "52e45b2cb00547119b2aa168ccc432a6",
            "0d7db1e74eb449bf9e28a9e9c3a26036",
            "a4e8423578a94e78818e67dd1fe91b0e",
            "4cf45153f6d44502a8ef360068290091",
            "af25ac70b0654886804c79d8441dc3f4",
            "cad8ac991f0549e19aba626e9e73e5e1",
            "6beed48ffff34eb38c0b520684df0cd4",
            "a29d97b727174487aad6493f1c8beffd",
            "43f9e5b9f9864c9ab9bee5e461e78195",
            "b5a62c84dc7a4bfa8075c1cbb732bc1c",
            "3ce9ec37a70543338c25be5dcf41fe1a",
            "2d841e3a8abf42cb82f12e3c58c50ed2",
            "790de83c5e3c4acdb7815247fd759f56",
            "765f0bb4cbb1405ba9c03fcd17e034a1",
            "2402801602ce4f0eaf6fd766d87c3367",
            "34c37ba749124077b9b182b84809b377",
            "ea950eec88d445fc992d3af320110952",
            "42e9ca9403314f7b9c53b7c5d4ea703a",
            "661dba0725ec417b9d448752e9ed7f0b",
            "1eb75e7497f94a18aebd4422de828682",
            "25704fe32e1b42cc8024b4b93d49d0de",
            "c0ada1ec4626413e861c2fa4c391f417",
            "901a2410ed3e476aaa299f597626810f",
            "a589900c7cc04da9b38807bb7e555777",
            "dbc51bd78f8040a88a682993d571608c",
            "f59d01831722416482c58e8969d9f9db",
            "b42bd23ee6e841859c7e24e9aa9baa42",
            "0bbc130c360346a4a9624702907cc19a",
            "e2d5070895ae48bf9ede25ce4159c5e7",
            "50939fd721aa4664b199856baf5375f4",
            "ac808ee69e5f4753a15b293038ba72ad",
            "9d36689e80254f08aab9fb609a8dfd2b",
            "3b1345192a4b4d14b8c5c79dc087fa22",
            "ac51e8c5ebb641c7b936714b4325baca",
            "030949b766cc4dae9c4b7bfd64bfe1aa",
            "d58198eb454f4ae89c9392870c0577ba",
            "42c3d464f7e74e3399f22baa8bf6a1fe",
            "225d4b84fb724456a57b738bacc3b2e8",
            "9bee185ddaeb4b6db5168ff5a23fc63d",
            "44e373b0f84947f2a377da58ee0c5f6b",
            "99eababf90d045ae97ef14b569f08acc",
            "bb5a8b7254d64ef6931f51b45986afc2",
            "7e7896e91ac646e788988a0f5c512de9",
            "d473825465e9497681f87130e7baf9af",
            "dbf298610c6941bfab1c71415ae76566",
            "bd85e4297cd849a5a675c150b8f6aca3",
            "af265edc4f4742b4bf52a529d7e6fe2a",
            "ee9d7a20e94a46f9af8be5bcec863272",
            "afdac9682e2d4518a2faf0acdc862d66",
            "32ae4b95068e4db1820502b0064194ce",
            "7cde4a7cd3664834b56035ab753973ae",
            "9e5a1ca123184fbaa4f4356bbc6abef9",
            "ca72069833754d04ae8d7d8ed27b41f4",
            "b74cd98049a14519bcccc986012332c1",
            "c7cfd1997a3a496eb2ab8cb37ced2d4e",
            "27dc27daf5de4bf29546b059a05673e8",
            "5c90a2e7fb104a61b47283846035586c",
            "95eb0f1715ab4927896b87c0c03f77a6",
            "2abe51451ec540b7aad3ffcb972bfe30",
            "1b08b53167284128a8c0f2e385931fb5",
            "667f0a841f494eb29abae24220b0c3d8",
            "4811907bbcff43cdbd5c19dee8543687",
            "e893d3a0e79b44a6afaf50d161331a23",
            "a904fb75998c455fbae92b3e3b9da012",
            "6d08113b77584f40a5e8f193426578c3",
            "a3a864e9a15e43478669eb866502b7be",
            "3e81dcd354c046709833d61323029acd",
            "bbc5081ec1254582b587500be6611a75",
            "eca6bb64273c4937b69e6c98b30ce622",
            "8e1b108ed33d459699c58698a45782ac",
            "87cf0432208e442699d89d78eec0cf55",
            "5c678a9294d64f27b26570626bda7121",
            "38bdb71377ab44d3ac220804dc84c2f2",
            "1698f60333e84b809ce40a66586bcb8a",
            "a9491efb1f994b6e87383a82059b6aba",
            "8d0ccc4e2d7644fcb8cd997686415bc2",
            "87ff53be0dec455b978a063ac7e0d222",
            "1f420f4c4e064560bbfd0696f922bdfa",
            "eb580e0a4f13491aa46b459eb2479f2d",
            "04d3b2d05542431f926ea41307305afa",
            "d249360d3f014d6a9de5b4869fc4fd30",
            "b9b520cab0b04d7090d0df16a1b80702",
            "c351dc6506f14466acb6350300b40d6c",
            "b34c4da6f77f45629bf874b91da0ad12",
            "e00b140a118c4ed1a7041bbdb2cdce6f",
            "fbc0b2757e1444acb1acf67d9b522e0e",
            "6430fd9da0a34af882e9f32c5b46534b",
            "a1aeba403af94168aeda82f7597e58d1",
            "15d8843d154f480897ade7ceedb21c48",
            "06afff649d2b4be181535cbcf3a75322",
            "b625d674741f4d918905a885ff9128f1",
            "f9cb14d396624859acf622675881de0a",
            "865f2e9325894b938c6d5d34a696a7a8",
            "407f4291733b4192aa96635c5b9ff3b1",
            "031b355a18434ed5bfe279a641d4d68d",
            "492744378deb44c29b75f13e6badc256",
            "8628f8e7ac484c65a30b8317205f52a9",
            "ab89e5692680427b98eaf5b1cf4fe02c",
            "b80060d2b4314636958a7c1c33be8ea8",
            "15d5cddd2cd447fa9c18d3a223309258",
            "0c0a0caee7d344acb8af6144cd5eeded",
            "b7242f69d0fd4a7c86f12543efd1cedb",
            "0537cf53230145a8bc5e9d8c03dc60ef",
            "936495a5245f4e1b8886b6e3debcb45d",
            "5a353f5aabe34eda858979ad304f28ae",
            "1bf631282c0543fe84c5bab02865e993",
            "81152c443bff44998f0da05ee28e0c78",
            "4be1de9ef2864059ac824fb4892c1af7",
            "d49439e9282e4eaea43bc0457c8b30d4",
            "ad918ee2fd7d4b31af8679b953744595",
            "dd09ad85121d423ab54cbcca0a6443b2",
            "d9176340a3af487da7a89a7e84058db4",
            "b32861d110fd47ddbc893d107c5ee98d",
            "796e1c32705748979b76b58507425e65",
            "7416a1360c7647d3a197409f0c74db50",
            "0123aa9fee5243d2b02c197c83d0c689",
            "370e7dbbb47848718d41a35893879a65",
            "0f3e304fa61a4d48bda2aebfe135ee04",
            "102de882e5024e05822099201dad57ef",
            "c991f66dc8c74ec582cbe68593abd64d",
            "381e9892c674462f9a365f06847dc938",
            "5c7ba19028a54e3487ff77cfc45c7035",
            "70d518fce5614c13a1be259d8fc3e3c6",
            "52511de3fcc24b00be6ba9a249bb5b7c",
            "b19bf32105394203b238542a54995425",
            "07cd021656b94de8a00fa9f663239290",
            "cfbbcb764a114a34b99d8019b8923a76",
            "c2579621823e4b46bcdc87f5194789af",
            "45b8f989d36841778c60b4493f0842e0"
          ]
        },
        "id": "R_O04fKxMMT-",
        "outputId": "111ca347-d97d-4be2-d1b3-e1a8d8c2affb"
      },
      "outputs": [],
      "source": [
        "# Load the Tokenizer and the Model\n",
        "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL, trust_remote_code=True)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"right\"\n",
        "\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    BASE_MODEL,\n",
        "    quantization_config=quant_config,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "base_model.generation_config.pad_token_id = tokenizer.pad_token_id\n",
        "\n",
        "print(f\"Memory footprint: {base_model.get_memory_footprint() / 1e6:.1f} MB\")  # Memory footprint: 5591.5 MB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BYO0If4uWys"
      },
      "source": [
        "## Data Collator\n",
        "\n",
        "It's important that we ensure during Training that we are not trying to train the model to predict the description of products; only their price.\n",
        "\n",
        "We need to tell the trainer that everything up to \"Price is $\" is there to give context to the model to predict the next token, but does not need to be learned.\n",
        "\n",
        "The trainer needs to teach the model to predict the token(s) after \"Price is $\".\n",
        "\n",
        "There is a complicated way to do this by setting Masks, but luckily HuggingFace provides a super simple helper class to take care of this for us."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2omVEaPIVJZa"
      },
      "outputs": [],
      "source": [
        "from trl import DataCollatorForCompletionOnlyLM\n",
        "response_template = \"Price is $\"\n",
        "collator = DataCollatorForCompletionOnlyLM(response_template, tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DaOeBhyy9eS"
      },
      "source": [
        "## Training configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset = load_dataset(DATASET_NAME)\n",
        "train = dataset['train']\n",
        "test = dataset['test']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# reduce the training dataset to 2K points instead of the full 400K points\n",
        "train = train.select(range(2000))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We need to create 2 objects:\n",
        "- A LoraConfig object with our hyperparameters for LoRA\n",
        "- An SFTConfig with our overall Training parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "343161d80043413d9fac5c00ac269f5e",
            "7f65fad67cae40968e87fa68ad177385",
            "63d80effada34c229796bd984c53303b",
            "a178798bf3ba478c8b05c22b5f85558b",
            "826132246c8a4790bfdd73510288cf63",
            "1dcda900072c496c8e37034faa8c6d8e",
            "822f8b471f904a13add7a87ea851ddba",
            "b9f6190d4a9844389a2bfcfbc2f3d25e",
            "0cd62f5664f4438da9634cbc0546504e",
            "643cf6fec40f40c2b681a60f643c29b9",
            "eda9db3d050e4a0daa7232817e9e4b1e"
          ]
        },
        "id": "fCwmDmkSATvj",
        "outputId": "865956e5-e430-4b8e-dbee-5c9bba99ca1d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "343161d80043413d9fac5c00ac269f5e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# First, specify the configuration parameters for LoRA\n",
        "lora_parameters = LoraConfig(\n",
        "    lora_alpha=LORA_ALPHA,\n",
        "    lora_dropout=LORA_DROPOUT,\n",
        "    r=LORA_R,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        "    target_modules=TARGET_MODULES,\n",
        ")\n",
        "\n",
        "# Next, specify the general configuration parameters for training\n",
        "train_parameters = SFTConfig(\n",
        "    output_dir=PROJECT_RUN_NAME,\n",
        "    num_train_epochs=EPOCHS,\n",
        "    per_device_train_batch_size=BATCH_SIZE,\n",
        "    per_device_eval_batch_size=1,\n",
        "    eval_strategy=\"no\",\n",
        "    gradient_accumulation_steps=GRADIENT_ACCUMULATION_STEPS,\n",
        "    optim=OPTIMIZER,\n",
        "    save_steps=SAVE_STEPS,\n",
        "    save_total_limit=10,\n",
        "    logging_steps=STEPS,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    weight_decay=0.001,\n",
        "    fp16=False,\n",
        "    bf16=True,\n",
        "    max_grad_norm=0.3,\n",
        "    max_steps=-1,\n",
        "    warmup_ratio=WARMUP_RATIO,\n",
        "    group_by_length=True,\n",
        "    lr_scheduler_type=LR_SCHEDULER_TYPE,\n",
        "    report_to=\"wandb\" if LOG_TO_WANDB else None,\n",
        "    run_name=RUN_NAME,\n",
        "    max_seq_length=MAX_SEQUENCE_LENGTH,\n",
        "    dataset_text_field=\"text\",\n",
        "    save_strategy=\"steps\",\n",
        "    hub_strategy=\"every_save\",\n",
        "    push_to_hub=True,\n",
        "    hub_model_id=HUB_MODEL_NAME,\n",
        "    hub_private_repo=True\n",
        ")\n",
        "\n",
        "# And now, the Supervised Fine Tuning Trainer will carry out the fine-tuning\n",
        "# Given these 2 sets of configuration parameters\n",
        "# The latest version of trl is showing a warning about labels - please ignore this warning\n",
        "# But let me know if you don't see good training results (loss coming down).\n",
        "\n",
        "fine_tuning = SFTTrainer(\n",
        "    model=base_model,\n",
        "    train_dataset=train,\n",
        "    peft_config=lora_parameters,\n",
        "    args=train_parameters,\n",
        "    data_collator=collator\n",
        "  )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArjP7_OCQOin"
      },
      "source": [
        "## Fine-tuning!\n",
        "\n",
        "This will run for some time, uploading to the hub every SAVE_STEPS steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588,
          "referenced_widgets": [
            "8301f88341344d339999b0b76987b4d7",
            "6b06edf7b40c4988b49f5837d9f67a12",
            "47db06bc95144c13a0d4b298d36b9642",
            "a6a6c3c857b54f4cbcdac5e3242500af",
            "1dc3652491f94457b46c5e777d8ad59c",
            "461be455a081413385643b2f569ab8fd",
            "41b1493722a9437480a420a07fddbfb7",
            "fc030104b99b448a8c5479464ebdd706",
            "edf6dee2e34b4814b53ca75214485670",
            "5140088c89e54b50862930fb5cd51db8",
            "fceb16dcd39b4c27a02410f39d872a67",
            "be87d395a0f14f6fa736b2830842d462",
            "ba10b32dec6046f5b913a938b1aab4f0",
            "485864cfa817402983a77ea4949f863e",
            "65a5133588a849ffbde27a4915a552c1",
            "e268eee7cb1a4766a71eea0f1d1033b1",
            "3b2d8360530e4bcfb4e060d4c15235c3",
            "93b5225ef8ed47d4944a2ab828875ec0",
            "27e8410bc3094748aa256d4da8e0b731",
            "9a6aee179b1a47d6ad49ac7433d1c500",
            "76a454e039d343ebbc63994ae8f57872",
            "287e1c9dd8894c578959caa112b26022",
            "256d2eebf1724d428c69d2bf84a25eb4",
            "7b875f3af45d40b181046d96683f9a12",
            "fbe982979f44486380b8d8be281b1245",
            "2818ad113082401db681f78348f4bcad",
            "065ce6079a734c3582700b134596a665",
            "e5652f5d75754aeab2be16b2b0348b4f",
            "ff3373e07615412e815df1d4e619f0ce",
            "3905746f2b7649c48e951759f25ab4e9",
            "518b507546674f0f9d2b1e0ce1715696",
            "9aa1522c5ad94c8782b8c73eff278a80",
            "7059db27f8074733a5913aad686b1c38",
            "d7d9b155216247e3b0b38a4a4b9f7eee",
            "bbbe864d4a1a4191b8edfa630c101243",
            "47e3738eae2c4c1d824e4d67be73b9d6",
            "a2a27a4f06b7451cb37a291900927260",
            "abdd179b2d1047378a7c10826047b4b3",
            "8f85f0a544b5481093fd0bbb30efca6a",
            "ce91c7287bd94735bcfb4c007a17acc8",
            "1b704251f2c14574b9afd1226eb43ea6",
            "29b0a9f16c854accb4c485bdf22c8be3",
            "2ec3689e649a40b39e9645f8c0d73db7",
            "98560595f33547ea811941bc53f4c94c"
          ]
        },
        "id": "GfvAxnXPvB7w",
        "outputId": "ffa6df0c-e482-49b0-838e-fe3fd5174c3f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [500/500 1:42:40, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>2.054200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.980200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>1.903000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.849300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>1.911900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>1.952200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>1.870900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>1.850800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>1.884700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.868000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (pricer-2025-10-18_19.19.46/checkpoint-500)... Done. 3.5s\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8301f88341344d339999b0b76987b4d7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/1.69k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "be87d395a0f14f6fa736b2830842d462",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Processing Files (0 / 0)      : |          |  0.00B /  0.00B            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "256d2eebf1724d428c69d2bf84a25eb4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "New Data Upload               : |          |  0.00B /  0.00B            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d7d9b155216247e3b0b38a4a4b9f7eee",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  ...adapter_model.safetensors:  31%|###       | 33.5MB /  109MB            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "WARNING:huggingface_hub.hf_api:No files have been modified since last commit. Skipping to prevent empty commit.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved to the hub: pricer-2025-10-18_19.19.46\n"
          ]
        }
      ],
      "source": [
        "# Fine-tune!\n",
        "fine_tuning.train()\n",
        "\n",
        "# Push our fine-tuned model to Hugging Face\n",
        "fine_tuning.model.push_to_hub(PROJECT_RUN_NAME, private=True)\n",
        "print(f\"Saved to the hub: {PROJECT_RUN_NAME}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32vvrYRVAUNg"
      },
      "outputs": [],
      "source": [
        "if LOG_TO_WANDB:\n",
        "  wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## End of Part 2\n",
        "We're done with the fine-tuning. Now it's time to take it for a spin!\n",
        "\n",
        "In part 3, we'll test the fine-tuned model on the test set and contrast the prediction performance results against those of the frontier LLM models."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
